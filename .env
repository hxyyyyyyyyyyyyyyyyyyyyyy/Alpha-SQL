# ============================================
# LLM 模型配置
# ============================================
OPENAI_API_KEY=your-api-key-here
OPENAI_BASE_URL=https://api.openai.com/v1

# ============================================
# Embedding 模型配置
# ============================================
# 必填: Embedding 模型名称
EMBEDDING_MODEL=text-embedding-3-large

# 可选: 如果 embedding 使用不同的 API 服务,请配置以下项
# 如果不配置,会自动使用上面的 OPENAI_API_KEY 和 OPENAI_BASE_URL
# EMBEDDING_API_KEY=your-embedding-api-key
# EMBEDDING_BASE_URL=https://your-embedding-service.com/v1

# ============================================
# WandB 配置 (可选)
# ============================================
# WANDB_API_KEY=your-wandb-api-key

# ============================================
# 配置示例
# ============================================

# 示例 1: LLM 用本地 VLLM, Embedding 用 OpenAI
# OPENAI_API_KEY=EMPTY
# OPENAI_BASE_URL=http://0.0.0.0:9999/v1
# EMBEDDING_MODEL=text-embedding-3-large
# EMBEDDING_API_KEY=sk-proj-xxxxx
# EMBEDDING_BASE_URL=https://api.openai.com/v1

# 示例 2: 全部使用 OpenAI
# OPENAI_API_KEY=sk-proj-xxxxx
# OPENAI_BASE_URL=https://api.openai.com/v1
# EMBEDDING_MODEL=text-embedding-3-large

# 示例 3: 全部本地部署,不同端口
# OPENAI_API_KEY=EMPTY
# OPENAI_BASE_URL=http://localhost:9999/v1
# EMBEDDING_MODEL=bge-large-zh-v1.5
# EMBEDDING_API_KEY=EMPTY
# EMBEDDING_BASE_URL=http://localhost:8080/v1


WEAVE_PRINT_CALL_LINK="False"